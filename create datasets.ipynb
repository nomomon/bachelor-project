{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc3aeda-6e4e-4b40-8285-67b89d94d47f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from src.dataset import DepressionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eefadd1b-8a86-4a13-a320-7f075d6c9f7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './data/gold' already exists.\n"
     ]
    }
   ],
   "source": [
    "# make a directory if it doesn't exist\n",
    "dataset_path = './data/gold'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "    print(f\"Directory '{dataset_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Directory '{dataset_path}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b33f1a1-cd35-463a-84ae-0face2483872",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_pid_1</td>\n",
       "      <td>Waiting for my mind to have a breakdown once t...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_pid_2</td>\n",
       "      <td>My new years resolution : I'm gonna get my ass...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_pid_3</td>\n",
       "      <td>New year : Somone else Feeling like 2020 will ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_pid_4</td>\n",
       "      <td>My story I guess : Hi, Im from Germany and my ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_pid_5</td>\n",
       "      <td>Sat in the dark and cried myself going into th...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pid                                               text     label\n",
       "0  train_pid_1  Waiting for my mind to have a breakdown once t...  moderate\n",
       "1  train_pid_2  My new years resolution : I'm gonna get my ass...  moderate\n",
       "2  train_pid_3  New year : Somone else Feeling like 2020 will ...  moderate\n",
       "3  train_pid_4  My story I guess : Hi, Im from Germany and my ...  moderate\n",
       "4  train_pid_5  Sat in the dark and cried myself going into th...  moderate"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = pd.read_table(\"./data/bronze/train.tsv\", sep=\"\\t\").groupby(\"label\").head(2000).reset_index(drop=True)\n",
    "raw_test = pd.read_table(\"./data/bronze/test.tsv\", sep=\"\\t\")\n",
    "raw_dev = pd.read_table(\"./data/bronze/dev.tsv\", sep=\"\\t\")\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39a7b8a7-1d31-4650-9603-ce20e9c7eca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as w2v_api\n",
    "\n",
    "w2v_model = w2v_api.load(\"word2vec-google-news-300\")\n",
    "w2v_vocab = w2v_model.key_to_index\n",
    "\n",
    "w2v_sample_words = np.random.choice(list(w2v_vocab.keys()), 100_000)\n",
    "w2v_sample_vectors = w2v_model[w2v_sample_words]\n",
    "w2v_mean = w2v_sample_vectors.mean(axis=0)\n",
    "w2v_std = w2v_sample_vectors.std(axis=0)\n",
    "\n",
    "def w2v_encoder(word_list):\n",
    "    encoded_words = []\n",
    "\n",
    "    for word in word_list:\n",
    "        if word in w2v_vocab:\n",
    "            encoded_word = w2v_model[word]\n",
    "        else:\n",
    "            # sample random gaussian vector\n",
    "            encoded_word = np.random.normal(loc=w2v_mean, scale=w2v_std)\n",
    "        encoded_words.append(encoded_word)\n",
    "\n",
    "    return np.asarray(encoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "896b8123-b203-45d0-8d75-1a30f748e5ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def window_encoder(word_list, window_size=11):\n",
    "    if window_size % 2 != 1:\n",
    "        raise Exception(\"window_size should be odd\")\n",
    "    half_window_size = (window_size - 1) // 2\n",
    "\n",
    "    edge_indices = []\n",
    "    for i in range(len(word_list)):\n",
    "        for j in range(-half_window_size, half_window_size + 1):\n",
    "            if i + j < 0 or i + j >= len(word_list):\n",
    "                continue\n",
    "            edge_indices.append([i, i + j])\n",
    "            edge_indices.append([i + j, i])\n",
    "    return edge_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a187b860-7e35-40e0-8481-caca252d554c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "100%|██████████| 4872/4872 [00:21<00:00, 229.72it/s]\n",
      "Done!\n",
      "Processing...\n",
      "100%|██████████| 3245/3245 [00:18<00:00, 174.48it/s]\n",
      "Done!\n",
      "Processing...\n",
      "100%|██████████| 4496/4496 [00:26<00:00, 172.18it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_root = dataset_path + \"/w2v_window_11\"\n",
    "\n",
    "for slice_name, dataset_slice in [\n",
    "    (\"train\", raw_train),\n",
    "    (\"test\", raw_test),\n",
    "    (\"dev\", raw_dev)\n",
    "]:\n",
    "    DepressionDataset(\n",
    "        root=dataset_root, filename=\"\",\n",
    "        prefix=slice_name,\n",
    "        word_encoder=w2v_encoder,\n",
    "        graph_encoder=window_encoder,\n",
    "        raw_data=dataset_slice\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c3af3da-b8c8-4d2c-9f5b-c229f3a76f88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "create datasets",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
