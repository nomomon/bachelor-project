{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mlflow\n",
    "from sklearn.metrics import confusion_matrix as sk_cm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.models.LSTM import LSTM\n",
    "from src.features.dataset_seq import DepressionDataset, collate_fn, get_sampler\n",
    "from src.train_seq import run_epoch\n",
    "\n",
    "from main import plot_cm, get_metrics\n",
    "\n",
    "mlflow.set_tracking_uri(\"../mlruns/\")\n",
    "mlflow.set_experiment(\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"encoder_type\": \"w2v\",\n",
    "    \"num_classes\": 3 - 1, # bcs of coral\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 100,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 5e-4,\n",
    "}\n",
    "\n",
    "# EMBEDDING DIMENSION\n",
    "if params[\"encoder_type\"] == \"bert\":\n",
    "    params[\"embedding_dim\"] = 768\n",
    "elif params[\"encoder_type\"] == \"w2v\":\n",
    "    params[\"embedding_dim\"] = 300\n",
    "else:\n",
    "    raise ValueError(\"Invalid encoder type\")\n",
    "\n",
    "# DEVICE\n",
    "if torch.backends.mps.is_available():\n",
    "    params[\"device\"] = torch.device(\"mps\")\n",
    "else:\n",
    "    params[\"device\"] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", params[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DepressionDataset('train', params[\"encoder_type\"], root_path=\"..\")\n",
    "valid = DepressionDataset('valid', params[\"encoder_type\"], root_path=\"..\")\n",
    "test  = DepressionDataset('test', params[\"encoder_type\"],  root_path=\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=params[\"batch_size\"], collate_fn=collate_fn, sampler=get_sampler(train))\n",
    "valid_loader = DataLoader(valid, batch_size=params[\"batch_size\"], collate_fn=collate_fn, shuffle=False)\n",
    "test_loader  = DataLoader(test,  batch_size=params[\"batch_size\"], collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(\n",
    "    params[\"num_classes\"], \n",
    "    params[\"embedding_dim\"],\n",
    "    params[\"hidden_dim\"], \n",
    ").to(params[\"device\"])\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr = params[\"learning_rate\"], \n",
    "    weight_decay = params[\"weight_decay\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.start_run()\n",
    "mlflow.log_params(params)\n",
    "\n",
    "valid_loss_hist = []\n",
    "for epoch in range(params[\"epochs\"]):\n",
    "    model.train()\n",
    "    y_true, y_pred, train_loss = run_epoch(model, train_loader, optimizer, params[\"device\"], epoch, 'train')\n",
    "    train_cm = sk_cm(y_true, y_pred, labels=[0, 1, 2], normalize='true')\n",
    "    mlflow.log_metrics(get_metrics(y_true, y_pred, \"train\"), step=epoch)\n",
    "    mlflow.log_metric(\"train.loss\", train_loss, step=epoch)\n",
    "\n",
    "    # Valid\n",
    "    model.eval()\n",
    "    y_true, y_pred, valid_loss = run_epoch(model, valid_loader, optimizer, params[\"device\"], epoch, 'valid')\n",
    "    valid_cm = sk_cm(y_true, y_pred, labels=[0, 1, 2], normalize='true')\n",
    "    mlflow.log_metrics(get_metrics(y_true, y_pred, \"valid\"), step=epoch)\n",
    "    mlflow.log_metric(\"valid.loss\", valid_loss, step=epoch)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm_path = plot_cm([\n",
    "        [train_cm, \"Train\"],\n",
    "        [valid_cm, \"Valid\"]\n",
    "    ], epoch, root=\"../reports/figures\")\n",
    "    mlflow.log_artifact(cm_path, artifact_path=\"confusion_matrix\")\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch > 4 and valid_loss > max(valid_loss_hist[-3:]):\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    valid_loss_hist.append(valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test\n",
    "model.eval()\n",
    "y_true, y_pred, test_loss = run_epoch(model, test_loader, optimizer, params[\"device\"], epoch, 'test')\n",
    "test_cm = sk_cm(y_true, y_pred, labels=[0, 1, 2], normalize='true')\n",
    "mlflow.log_metrics(get_metrics(y_true, y_pred, \"test\"), step=epoch)\n",
    "mlflow.log_metric(\"test.loss\", test_loss, step=epoch)\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_path = plot_cm([\n",
    "    [test_cm, \"Test\"]\n",
    "], 999, root=\"../reports/figures\")\n",
    "mlflow.log_artifact(cm_path, artifact_path=\"confusion_matrix\")\n",
    "\n",
    "# Save model to mlflow\n",
    "mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-mpzZBFSK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
