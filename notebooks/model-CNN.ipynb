{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.models.CNN import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 5e-4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "FILTERS = 64\n",
    "NUMBER_OF_CLASSES = 3\n",
    "ENCODER_TYPE = \"bert\"\n",
    "\n",
    "embedding_size = 768 if ENCODER_TYPE == \"bert\" else (300 if ENCODER_TYPE == \"w2v\" else ValueError(\"Invalid encoder type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DepressionDataset(Dataset):\n",
    "    def __init__(self, set_type, encoder_type, root_path=\".\"):\n",
    "        \n",
    "        self.set_type = set_type\n",
    "        self.encoder_type = encoder_type\n",
    "        self.root_path = root_path\n",
    "\n",
    "        self.raw_dir = os.path.join(root_path, \"data\", \"gold\", set_type, \"raw\")\n",
    "\n",
    "        assert os.path.exists(self.raw_dir), f\"Path {self.raw_dir} does not exist\"\n",
    "\n",
    "        self.sample_weights = self.get_sample_weights()\n",
    "\n",
    "    def __len__(self):\n",
    "        dirs = os.listdir(self.raw_dir)\n",
    "        dirs = [d for d in dirs if os.path.isdir(os.path.join(self.raw_dir, d))]\n",
    "        return len(dirs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = str(idx)\n",
    "        features_path = os.path.join(self.raw_dir, idx, f\"features_{self.encoder_type}.npy\")\n",
    "        label_path = os.path.join(self.raw_dir, idx, \"label.pkl\")\n",
    "\n",
    "        features = np.load(features_path)\n",
    "        label = pickle.load(open(label_path, \"rb\"))\n",
    "\n",
    "        features = torch.from_numpy(features).float()\n",
    "        label = torch.tensor(label).long()\n",
    "\n",
    "        return features, label\n",
    "    \n",
    "    def get_sample_weights(self):\n",
    "        labels = []\n",
    "        for idx in range(len(self)):\n",
    "            idx = str(idx)\n",
    "            label_path = os.path.join(self.raw_dir, idx, \"label.pkl\")\n",
    "            label = pickle.load(open(label_path, \"rb\"))\n",
    "            labels.append(label)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        class_weights = np.zeros(np.unique(labels).shape[0])\n",
    "        for i in range(len(class_weights)):\n",
    "            class_weights[i] = len(labels) / np.sum(labels == i)\n",
    "        \n",
    "        sample_weights = class_weights[labels]\n",
    "\n",
    "        return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DepressionDataset('train', ENCODER_TYPE, root_path=\"..\")\n",
    "valid = DepressionDataset('valid', ENCODER_TYPE, root_path=\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # padd features to same length\n",
    "    features, labels = zip(*batch)\n",
    "    features = torch.nn.utils.rnn.pad_sequence(features, batch_first=True)\n",
    "    return features, torch.stack(labels)\n",
    "\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(\n",
    "    weights=train.sample_weights,\n",
    "    num_samples=len(train.sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, sampler=sampler, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid, batch_size=BATCH_SIZE, shuffle=False,   collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(NUMBER_OF_CLASSES-1, FILTERS, embedding_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from coral_pytorch.losses import corn_loss\n",
    "from coral_pytorch.dataset import corn_label_from_logits\n",
    "\n",
    "def run_epoch(model, loader, optimizer, device, epoch, set_type):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_loss = 0\n",
    "\n",
    "    if set_type == 'train':\n",
    "        desc = f'Epoch {epoch:3d} ┬ Train'\n",
    "    elif set_type == 'valid':\n",
    "        desc = '          └ Valid'\n",
    "\n",
    "    for b in tqdm(loader, desc=desc):\n",
    "        x, y = b\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = corn_loss(out, y, num_classes=3)\n",
    "\n",
    "        pred = corn_label_from_logits(out)\n",
    "\n",
    "        y_true += y.tolist()\n",
    "        y_pred += pred.cpu().tolist()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if set_type == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    epoch_loss /= len(loader)\n",
    "\n",
    "    return y_true, y_pred, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix as sk_cm\n",
    ")\n",
    "from main import get_metrics, plot_cm\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# mlflow.set_tracking_uri(\"../mlruns\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"CNN\")\n",
    "\n",
    "with mlflow.start_run():    \n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"weight_decay\", WEIGHT_DECAY)\n",
    "    mlflow.log_param(\"filters\", FILTERS)\n",
    "    mlflow.log_param(\"encoder_type\", ENCODER_TYPE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        y_true, y_pred, train_loss = run_epoch(model, train_loader, optimizer, device, epoch, 'train')\n",
    "        train_cm = sk_cm(y_true, y_pred, labels=[0, 1, 2], normalize='true')\n",
    "        mlflow.log_metrics(get_metrics(y_true, y_pred, \"train\"), step=epoch)\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "\n",
    "        # Valid\n",
    "        model.eval()\n",
    "        y_true, y_pred, valid_loss = run_epoch(model, valid_loader, optimizer, device, epoch, 'valid')\n",
    "        valid_cm = sk_cm(y_true, y_pred, labels=[0, 1, 2], normalize='true')\n",
    "        mlflow.log_metrics(get_metrics(y_true, y_pred, \"valid\"), step=epoch)\n",
    "        mlflow.log_metric(\"valid_loss\", valid_loss, step=epoch)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        cm_path = plot_cm([\n",
    "            [train_cm, \"Train\"],\n",
    "            [valid_cm, \"Valid\"]\n",
    "        ], epoch, root=\"../reports/figures\")\n",
    "        mlflow.log_artifact(cm_path, artifact_path=\"confusion_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-mpzZBFSK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
