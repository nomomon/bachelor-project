{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as F\n",
    "from torch_geometric.loader import DataLoader, ImbalancedSampler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.features.dataset import DepressionDataset\n",
    "from src.models.CNN import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 5e-4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "FILTERS = 100\n",
    "NUMBER_OF_CLASSES = 3\n",
    "ENCODER_TYPE = \"bert\"\n",
    "\n",
    "embedding_size = 768 if ENCODER_TYPE == \"bert\" else (300 if ENCODER_TYPE == \"w2v\" else ValueError(\"Invalid encoder type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DepressionDataset('train', ENCODER_TYPE, \"other\", root_path=\"..\")\n",
    "valid = DepressionDataset('valid', ENCODER_TYPE, \"other\", root_path=\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ImbalancedSampler(train, len(train))\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "valid_loader = DataLoader(valid, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(NUMBER_OF_CLASSES-1, FILTERS, embedding_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(b):\n",
    "    x = b.x.to(device)\n",
    "    batch = b.batch.to(device)\n",
    "\n",
    "    # longest sentence in the batch\n",
    "    max_len = torch.max(batch.bincount())\n",
    "\n",
    "    # number of sentences in the batch\n",
    "    num_sentences = batch[-1].item() + 1\n",
    "\n",
    "    # create a new tensor with the correct shape\n",
    "    x_new = torch.zeros((num_sentences, max_len, x.shape[1])).to(device)\n",
    "    \n",
    "    # fill the new tensor with the old values\n",
    "    for i in range(num_sentences):\n",
    "        x_new[i, :batch.bincount()[i]] = x[batch == i]\n",
    "\n",
    "    return x_new, b.y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from coral_pytorch.losses import corn_loss\n",
    "from coral_pytorch.dataset import corn_label_from_logits\n",
    "\n",
    "def run_epoch(model, loader, optimizer, device, epoch, set_type):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    epoch_loss = 0\n",
    "\n",
    "    if set_type == 'train':\n",
    "        desc = f'Epoch {epoch:3d} ┬ Train'\n",
    "    elif set_type == 'valid':\n",
    "        desc = '          └ Valid'\n",
    "\n",
    "    for b in tqdm(loader, desc=desc):\n",
    "        x, y = collate_fn(b)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = corn_loss(out, y, num_classes=3)\n",
    "        \n",
    "        if set_type == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pred = corn_label_from_logits(out)\n",
    "\n",
    "        y_true += y.tolist()\n",
    "        y_pred += pred.cpu().tolist()\n",
    "        epoch_loss += loss.item()\n",
    "    epoch_loss /= len(loader)\n",
    "\n",
    "    return y_true, y_pred, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   0 ┬ Train:   0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   0 ┬ Train:   2%|▏         | 1/49 [00:25<20:29, 25.61s/it]"
     ]
    }
   ],
   "source": [
    "from main import get_metrics, plot_cm\n",
    "import mlflow\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix as sk_cm\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "mlflow.set_experiment(\"CNN\")\n",
    "\n",
    "with mlflow.start_run():    \n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
    "    mlflow.log_param(\"weight_decay\", WEIGHT_DECAY)\n",
    "    mlflow.log_param(\"filters\", FILTERS)\n",
    "    mlflow.log_param(\"encoder_type\", ENCODER_TYPE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        y_true, y_pred, train_loss = run_epoch(model, train_loader, optimizer, device, epoch, 'train')\n",
    "        train_cm = sk_cm(y_true, y_pred, labels=[0, 1, 2], normalize='true')\n",
    "        mlflow.log_metrics(get_metrics(y_true, y_pred, \"train\"), step=epoch)\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "\n",
    "        # Valid\n",
    "        model.eval()\n",
    "        y_true, y_pred, valid_loss = run_epoch(model, valid_loader, optimizer, device, epoch, 'valid')\n",
    "        valid_cm = sk_cm(y_true, y_pred, labels=[0, 1, 2], normalize='true')\n",
    "        mlflow.log_metrics(get_metrics(y_true, y_pred, \"valid\"), step=epoch)\n",
    "        mlflow.log_metric(\"valid_loss\", valid_loss, step=epoch)\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        cm_path = plot_cm(train_cm, valid_cm, epoch, root=\"../reports/figures\")\n",
    "        mlflow.log_artifact(cm_path, artifact_path=\"confusion_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-mpzZBFSK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
